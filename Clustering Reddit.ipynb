{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Projet de Données à la Connaissance\n",
    "======\n",
    "\n",
    "## Introduction\n",
    "\n",
    "## Choix de l'algorithme de clustering\n",
    "DBSCAN \n",
    "raison du choix :\n",
    "- Non-flat geometry, \n",
    "- uneven cluster sizes\n",
    "- Très scalable\n",
    "- Nombre de clusters inconnus (vs K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/quentin/anaconda/lib/python3.6/site-packages/numexpr/cpuinfo.py:76: UserWarning: [Errno 2] No such file or directory: 'sysctl'\n",
      "  stacklevel=stacklevel + 1):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd # Ouverture des données\n",
    "import numpy as np \n",
    "import gensim # Pour lire word2vec\n",
    "import math\n",
    "import sys\n",
    "from scipy.sparse import dok_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouverture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posts loaded into dataframe\n",
      "Comments loaded into dataframe\n"
     ]
    }
   ],
   "source": [
    "df_posts=pd.read_csv(\"data/reddit_posts.csv\",sep=\";\", names=['Id','UserName','SubReddit','Title','Body'], header=None)\n",
    "print(\"Posts loaded into dataframe\")\n",
    "df_comments=pd.read_csv(\"data/reddit_comments.csv\",sep=\";\", names=['Id','UserName','SubReddit','Comment'], header=None)\n",
    "print(\"Comments loaded into dataframe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4468114\n",
      "   Id        UserName  SubReddit  \\\n",
      "0   1           SRASC      Honda   \n",
      "1   3         JRabone   Patriots   \n",
      "2   4         adamorn  AskReddit   \n",
      "3   5        JakeM917  doctorwho   \n",
      "4  10  DataScienceInc    pystats   \n",
      "\n",
      "                                               Title       Body  \n",
      "0                                     The new S2000?        NaN  \n",
      "1      I made a video for SB LI supporting our Pats!        NaN  \n",
      "2  Trump supporters - Do you feel that he is doin...  [removed]  \n",
      "3                         The 13th Doctor we deserve        NaN  \n",
      "4                        Introduction to Correlation        NaN  \n",
      "35561917\n",
      "   Id        UserName            SubReddit  \\\n",
      "0   1        crash787        pokemontrades   \n",
      "1   2    Cuntosaurous                  Amd   \n",
      "2   3         dwmills  KitchenConfidential   \n",
      "3   4  GodsGiftInBeef          LiverpoolFC   \n",
      "4   5       Smeeks765      ecigclassifieds   \n",
      "\n",
      "                                             Comment  \n",
      "0                        Regigigas and mega alakazam  \n",
      "1                     I think we deserve more time!   \n",
      "2  You looking for a gig? In Oak cliff may need s...  \n",
      "3               Just asking but being a dick helped   \n",
      "4              I am interested. What is your paypal?  \n"
     ]
    }
   ],
   "source": [
    "print(len(df_posts))\n",
    "print(df_posts.head())\n",
    "print(len(df_comments))\n",
    "print(df_comments.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.KeyedVectors.load_word2vec_format(\"data/GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Première approche : Clustering des SubReddits par NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deuxième approche : Clustering des SubReddits par Utilisateurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4468114 3330748 94288\n"
     ]
    }
   ],
   "source": [
    "df_posts_dropped = df_posts.drop(labels=['Title', 'Body'], axis=1)\n",
    "df_comments_dropped = df_comments.drop(labels='Comment', axis=1)\n",
    "\n",
    "users = df_posts_dropped[\"UserName\"].append(df_comments_dropped[\"UserName\"])\n",
    "users.drop_duplicates(inplace=True)\n",
    "nb_users = len(users)\n",
    "\n",
    "subreddits = df_posts_dropped[\"SubReddit\"].append(df_comments_dropped[\"SubReddit\"])\n",
    "subreddits.drop_duplicates(inplace=True)\n",
    "nb_subreddits = len(subreddits)\n",
    "\n",
    "print(len(df_posts_dropped), nb_users, nb_subreddits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UserName              SubReddit           \n",
      "-------------------c  Jokes                    1\n",
      "                      The_Donald               2\n",
      "                      television               1\n",
      "------------------GL  gifs                     1\n",
      "------------------ll  EnoughTrumpSpam          1\n",
      "                      MarchAgainstTrump        1\n",
      "                      politics                 1\n",
      "--------------_----_  Invites                  1\n",
      "----------J_Peterman  AskReddit                1\n",
      "----------_----       AskHistorians            1\n",
      "                      AskReddit                2\n",
      "                      gifs                     2\n",
      "                      skyrim                   1\n",
      "----------_--------   leagueoflegends          9\n",
      "                      wow                      3\n",
      "----------_-_-        Shitty_Car_Mods          1\n",
      "--------Link--------  books                    1\n",
      "                      funny                    1\n",
      "--------_-------      Fitness                  1\n",
      "                      northkorea               1\n",
      "--------__--------    Winnipeg                72\n",
      "--------cool--------  Fitness                 10\n",
      "                      ultimate                18\n",
      "-------1-             FULLCOMMUNISM            1\n",
      "-------_-----         AskReddit                1\n",
      "                      Competitiveoverwatch    12\n",
      "                      Futurology               2\n",
      "                      GlobalOffensive         26\n",
      "                      Jokes                    1\n",
      "                      OurPresident             2\n",
      "                                              ..\n",
      "zzzzzlb               analog                   1\n",
      "zzzzzuu               sousvide                 3\n",
      "                      wow                      3\n",
      "zzzzzxx               Addons4Kodi              2\n",
      "                      AskReddit                1\n",
      "                      Asterisk                 1\n",
      "                      Showerthoughts           1\n",
      "                      freepbx                  1\n",
      "                      kodi                     1\n",
      "zzzzzzoltan           TEFL                     1\n",
      "zzzzzzzasd            pornID                   1\n",
      "zzzzzzzz414           AskReddit                1\n",
      "                      Documentaries            1\n",
      "                      Showerthoughts           2\n",
      "                      homestuck                7\n",
      "                      news                     2\n",
      "                      nottheonion              2\n",
      "                      television               2\n",
      "                      worldnews                9\n",
      "zzzzzzzzlll           osugame                  1\n",
      "zzzzzzzzzzzzzzdz      singapore                2\n",
      "                      violinist                5\n",
      "zzzzzzzzzzzzzzzzspaf  AskEurope               11\n",
      "                      AskReddit               12\n",
      "                      Breath_of_the_Wild       1\n",
      "                      YUROP                    2\n",
      "                      europe                  19\n",
      "                      personalfinance          1\n",
      "                      sports                   1\n",
      "                      worldnews                1\n",
      "Name: Id, Length: 10722585, dtype: int64\n",
      "100000 5242992 589928\n",
      "200000 10485880 589928\n",
      "300000 10485880 589928\n",
      "400000 20971632 1310816\n",
      "500000 20971632 1310816\n",
      "600000 20971632 1310816\n",
      "700000 41943160 1310816\n",
      "800000 41943160 1310816\n",
      "900000 41943160 1310816\n",
      "1000000 41943160 1310816\n",
      "1100000 41943160 1310816\n",
      "1200000 41943160 1310816\n",
      "1300000 41943160 1310816\n",
      "1400000 83886192 1310816\n",
      "1500000 83886192 1310816\n",
      "1600000 83886192 1310816\n",
      "1700000 83886192 2621544\n",
      "1800000 83886192 2621544\n",
      "1900000 83886192 2621544\n",
      "2000000 83886192 2621544\n",
      "2100000 83886192 2621544\n",
      "2200000 83886192 2621544\n",
      "2300000 83886192 2621544\n",
      "2400000 83886192 2621544\n",
      "2500000 83886192 2621544\n",
      "2600000 83886192 2621544\n",
      "2700000 83886192 2621544\n",
      "2800000 167772280 2621544\n",
      "2900000 167772280 2621544\n",
      "3000000 167772280 2621544\n",
      "3100000 167772280 2621544\n",
      "3200000 167772280 2621544\n",
      "3300000 167772280 2621544\n",
      "3400000 167772280 2621544\n",
      "3500000 167772280 2621544\n",
      "3600000 167772280 2621544\n",
      "3700000 167772280 2621544\n",
      "3800000 167772280 2621544\n",
      "3900000 167772280 2621544\n",
      "4000000 167772280 2621544\n",
      "4100000 167772280 2621544\n",
      "4200000 167772280 2621544\n",
      "4300000 167772280 2621544\n",
      "4400000 167772280 2621544\n",
      "4500000 167772280 2621544\n",
      "4600000 167772280 2621544\n",
      "4700000 167772280 2621544\n",
      "4800000 167772280 2621544\n",
      "4900000 167772280 2621544\n",
      "5000000 167772280 2621544\n",
      "5100000 167772280 2621544\n",
      "5200000 167772280 2621544\n",
      "5300000 167772280 2621544\n",
      "5400000 167772280 2621544\n",
      "5500000 167772280 2621544\n",
      "5600000 335544432 2621544\n",
      "5700000 335544432 2621544\n",
      "5800000 335544432 2621544\n",
      "5900000 335544432 2621544\n",
      "6000000 335544432 2621544\n",
      "6100000 335544432 2621544\n",
      "6200000 335544432 2621544\n",
      "6300000 335544432 2621544\n",
      "6400000 335544432 2621544\n",
      "6500000 335544432 2621544\n",
      "6600000 335544432 2621544\n",
      "6700000 335544432 2621544\n",
      "6800000 335544432 2621544\n",
      "6900000 335544432 2621544\n",
      "7000000 335544432 2621544\n",
      "7100000 335544432 2621544\n",
      "7200000 335544432 2621544\n",
      "7300000 335544432 2621544\n",
      "7400000 335544432 2621544\n",
      "7500000 335544432 2621544\n",
      "7600000 335544432 2621544\n",
      "7700000 335544432 2621544\n",
      "7800000 335544432 2621544\n",
      "7900000 335544432 2621544\n",
      "8000000 335544432 2621544\n",
      "8100000 335544432 2621544\n",
      "8200000 335544432 2621544\n",
      "8300000 335544432 2621544\n",
      "8400000 335544432 2621544\n",
      "8500000 335544432 2621544\n",
      "8600000 335544432 2621544\n",
      "8700000 335544432 2621544\n",
      "8800000 335544432 2621544\n",
      "8900000 335544432 2621544\n",
      "9000000 335544432 2621544\n",
      "9100000 335544432 5242976\n",
      "9200000 335544432 5242976\n",
      "9300000 335544432 5242976\n",
      "9400000 335544432 5242976\n",
      "9500000 335544432 5242976\n",
      "9600000 335544432 5242976\n",
      "9700000 335544432 5242976\n",
      "9800000 335544432 5242976\n",
      "9900000 335544432 5242976\n",
      "10000000 335544432 5242976\n",
      "10100000 335544432 5242976\n",
      "10200000 335544432 5242976\n",
      "10300000 335544432 5242976\n",
      "10400000 335544432 5242976\n",
      "10500000 335544432 5242976\n",
      "10600000 335544432 5242976\n",
      "10700000 335544432 5242976\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "users_id, subreddits_id = {}, {}\n",
    "user_item_matrix = dok_matrix((nb_users, nb_subreddits), dtype=int)\n",
    "\n",
    "grouped_comments = df_posts_dropped.append(df_comments_dropped).groupby([\"UserName\",\"SubReddit\"])[\"Id\"].count()\n",
    "\n",
    "print(grouped_comments)\n",
    "c = 0\n",
    "for item in grouped_comments.iteritems():\n",
    "    c += 1\n",
    "    username = item[0][0]\n",
    "    subreddit = item[0][1]\n",
    "    try:\n",
    "        i = users_id[username]\n",
    "    except:\n",
    "        i = len(users_id)\n",
    "        users_id[username] = i\n",
    "    try:\n",
    "        j = subreddits_id[subreddit]\n",
    "    except:\n",
    "        j = len(subreddits_id)\n",
    "        subreddits_id[subreddit] = j\n",
    "    user_item_matrix[i, j] = int(math.ceil(math.log(1 + item[1])))\n",
    "    if c%100000 == 0:\n",
    "        print(c, sys.getsizeof(user_item_matrix), sys.getsizeof(subreddits_id))\n",
    "\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3330748\n",
      "(3330748, 94288)\n",
      "Transposed\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "print(len(users_id))\n",
    "print(user_item_matrix.shape)\n",
    "\n",
    "user_item_matrix = csr_matrix(user_item_matrix).transpose()\n",
    "print(\"Transposed\")\n",
    "\n",
    "db = MiniBatchKMeans(n_clusters=10).fit_predict(user_item_matrix)\n",
    "print(\"Finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoneWildTrans 9\n",
      "Tgifs 9\n",
      "GoneWildHairy 9\n",
      "Hotwife 9\n",
      "Femdom 9\n",
      "Cuckold 9\n",
      "FootFetish 9\n",
      "BdsmNsfw 9\n",
      "ChurchOfTheBBC 9\n",
      "Spanking 9\n",
      "HairyPussy 9\n",
      "CuckoldXxX 9\n",
      "facesitting 9\n",
      "BBCSluts 9\n",
      "POVPornVids 9\n",
      "Hairy 9\n",
      "cuckquean 9\n",
      "femdom_gifs 9\n",
      "Lesbian_Porn 9\n",
      "Lesbian_gifs 9\n",
      "shemale_gifs 9\n",
      "Shemale_vids 9\n",
      "shemalexxx 9\n",
      "hairy_girls 9\n",
      "SpankingPictures 9\n",
      "bdsm_gifs 9\n",
      "BDSM_Porn 9\n",
      "SpankingBottoms 9\n",
      "fartfetish 9\n",
      "AssJob 9\n",
      "HairyGirlAction 9\n",
      "shemalesporn 9\n",
      "MissBratPerversions 9\n",
      "Bisexualporn 9\n",
      "BDSMPornSites 9\n",
      "FartSniffing 9\n",
      "FootFetishGirls 9\n",
      "cuckoldporn2 9\n"
     ]
    }
   ],
   "source": [
    "for subreddit in subreddits_id:\n",
    "    cluster = db[subreddits_id[subreddit]]\n",
    "    if cluster == 9:\n",
    "        print(subreddit, cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
